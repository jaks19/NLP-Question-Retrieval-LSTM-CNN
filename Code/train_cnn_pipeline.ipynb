{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on batch #:  1\n",
      "loss_on_batch: 0.11598242074251175  time_on_batch: 47.58596754074097\n",
      "Working on batch #:  2\n",
      "loss_on_batch: 0.12181520462036133  time_on_batch: 86.50125551223755\n",
      "Working on batch #:  3\n",
      "loss_on_batch: 0.12739363312721252  time_on_batch: 59.125295877456665\n",
      "Working on batch #:  4\n",
      "loss_on_batch: 0.10834074020385742  time_on_batch: 48.775763511657715\n",
      "Working on batch #:  5\n",
      "loss_on_batch: 0.10965130478143692  time_on_batch: 71.73584389686584\n",
      "Working on batch #:  6\n",
      "loss_on_batch: 0.09836101531982422  time_on_batch: 40.69927406311035\n",
      "Working on batch #:  7\n",
      "loss_on_batch: 0.07860840857028961  time_on_batch: 42.42386484146118\n",
      "Working on batch #:  8\n",
      "loss_on_batch: 0.06777147203683853  time_on_batch: 37.37542939186096\n",
      "Working on batch #:  9\n",
      "loss_on_batch: 0.057408176362514496  time_on_batch: 31.820467233657837\n",
      "Working on batch #:  10\n",
      "loss_on_batch: 0.08326955139636993  time_on_batch: 50.56151223182678\n",
      "Working on batch #:  11\n",
      "loss_on_batch: 0.06095137074589729  time_on_batch: 41.09272813796997\n",
      "Working on batch #:  12\n",
      "loss_on_batch: 0.057142529636621475  time_on_batch: 69.5973687171936\n",
      "Working on batch #:  13\n",
      "loss_on_batch: 0.05521130934357643  time_on_batch: 46.64612078666687\n",
      "Working on batch #:  14\n",
      "loss_on_batch: 0.050937220454216  time_on_batch: 43.16962504386902\n",
      "Working on batch #:  15\n",
      "loss_on_batch: 0.04293262958526611  time_on_batch: 45.6290168762207\n",
      "Working on batch #:  16\n",
      "loss_on_batch: 0.04386960715055466  time_on_batch: 50.35875082015991\n",
      "Working on batch #:  17\n",
      "loss_on_batch: 0.03743869811296463  time_on_batch: 77.19460105895996\n",
      "Working on batch #:  18\n",
      "loss_on_batch: 0.07286769151687622  time_on_batch: 111.71628856658936\n",
      "Working on batch #:  19\n",
      "loss_on_batch: 0.04040269926190376  time_on_batch: 43.824625968933105\n",
      "Working on batch #:  20\n",
      "loss_on_batch: 0.03996942564845085  time_on_batch: 50.39403486251831\n",
      "Working on batch #:  21\n",
      "loss_on_batch: 0.034787844866514206  time_on_batch: 43.29217219352722\n",
      "Working on batch #:  22\n",
      "loss_on_batch: 0.037227071821689606  time_on_batch: 47.631715536117554\n",
      "Working on batch #:  23\n",
      "loss_on_batch: 0.03899412974715233  time_on_batch: 35.07431125640869\n",
      "Working on batch #:  24\n",
      "loss_on_batch: 0.035750627517700195  time_on_batch: 44.34798288345337\n",
      "Working on batch #:  25\n",
      "loss_on_batch: 0.025053605437278748  time_on_batch: 80.77077126502991\n",
      "Working on batch #:  26\n",
      "loss_on_batch: 0.040686048567295074  time_on_batch: 97.01910495758057\n",
      "Working on batch #:  27\n",
      "loss_on_batch: 0.02959728240966797  time_on_batch: 43.4144983291626\n",
      "Working on batch #:  28\n",
      "loss_on_batch: 0.012189140543341637  time_on_batch: 112.3478832244873\n",
      "Working on batch #:  29\n",
      "loss_on_batch: 0.0272061787545681  time_on_batch: 53.253674030303955\n",
      "Working on batch #:  30\n",
      "loss_on_batch: 0.03750237822532654  time_on_batch: 38.659849882125854\n",
      "Working on batch #:  31\n",
      "loss_on_batch: 0.03212198615074158  time_on_batch: 31.079652786254883\n",
      "Working on batch #:  32\n",
      "loss_on_batch: 0.024448074400424957  time_on_batch: 38.01613759994507\n",
      "Working on batch #:  33\n",
      "loss_on_batch: 0.01707286201417446  time_on_batch: 37.29020690917969\n",
      "Working on batch #:  34\n",
      "loss_on_batch: 0.02760268747806549  time_on_batch: 35.63379526138306\n",
      "Working on batch #:  35\n",
      "loss_on_batch: 0.028529930859804153  time_on_batch: 42.38676476478577\n",
      "Working on batch #:  36\n",
      "loss_on_batch: 0.02975294552743435  time_on_batch: 39.18624997138977\n",
      "Working on batch #:  37\n",
      "loss_on_batch: 0.020384132862091064  time_on_batch: 166.10489916801453\n",
      "Working on batch #:  38\n",
      "loss_on_batch: 0.025797249749302864  time_on_batch: 35.70899796485901\n",
      "Working on batch #:  39\n",
      "loss_on_batch: 0.02436300739645958  time_on_batch: 31.942980527877808\n",
      "Working on batch #:  40\n",
      "loss_on_batch: 0.02522900700569153  time_on_batch: 88.42186093330383\n",
      "Working on batch #:  41\n",
      "loss_on_batch: 0.022572653368115425  time_on_batch: 31.637166738510132\n",
      "Working on batch #:  42\n",
      "loss_on_batch: 0.020986929535865784  time_on_batch: 33.80794143676758\n",
      "Working on batch #:  43\n",
      "loss_on_batch: 0.026379883289337158  time_on_batch: 37.60303854942322\n",
      "Working on batch #:  44\n",
      "loss_on_batch: 0.02040092833340168  time_on_batch: 30.395862340927124\n",
      "Working on batch #:  45\n",
      "loss_on_batch: 0.02404450625181198  time_on_batch: 36.55825710296631\n",
      "Working on batch #:  46\n",
      "loss_on_batch: 0.03387891873717308  time_on_batch: 42.51510739326477\n",
      "Working on batch #:  47\n",
      "loss_on_batch: 0.029118474572896957  time_on_batch: 37.13679814338684\n",
      "Working on batch #:  48\n",
      "loss_on_batch: 0.019023442640900612  time_on_batch: 35.01014018058777\n",
      "Working on batch #:  49\n",
      "loss_on_batch: 0.02149156667292118  time_on_batch: 31.489776849746704\n",
      "Working on batch #:  50\n",
      "loss_on_batch: 0.023889509961009026  time_on_batch: 39.430870056152344\n",
      "Working on batch #:  51\n",
      "loss_on_batch: 0.02284647896885872  time_on_batch: 36.04389142990112\n",
      "Working on batch #:  52\n",
      "loss_on_batch: 0.02438545413315296  time_on_batch: 46.98800706863403\n",
      "Working on batch #:  53\n",
      "loss_on_batch: 0.02886752039194107  time_on_batch: 34.70733666419983\n",
      "Working on batch #:  54\n",
      "loss_on_batch: 0.028592213988304138  time_on_batch: 48.76172471046448\n",
      "Working on batch #:  55\n",
      "loss_on_batch: 0.026825791224837303  time_on_batch: 33.728731632232666\n",
      "Working on batch #:  56\n",
      "loss_on_batch: 0.019682038575410843  time_on_batch: 36.94528913497925\n",
      "Working on batch #:  57\n",
      "loss_on_batch: 0.021527575328946114  time_on_batch: 34.089691400527954\n",
      "Working on batch #:  58\n",
      "loss_on_batch: 0.01712694764137268  time_on_batch: 33.57632637023926\n",
      "Working on batch #:  59\n",
      "loss_on_batch: 0.019077666103839874  time_on_batch: 54.34658241271973\n",
      "Working on batch #:  60\n",
      "loss_on_batch: 0.018584582954645157  time_on_batch: 32.27586603164673\n",
      "Working on batch #:  61\n",
      "loss_on_batch: 0.017772585153579712  time_on_batch: 71.74085664749146\n",
      "Working on batch #:  62\n",
      "loss_on_batch: 0.019291063770651817  time_on_batch: 44.047181844711304\n",
      "Working on batch #:  63\n",
      "loss_on_batch: 0.02078930474817753  time_on_batch: 38.554975748062134\n",
      "Working on batch #:  64\n",
      "loss_on_batch: 0.0263007003813982  time_on_batch: 40.862709760665894\n",
      "Working on batch #:  65\n",
      "loss_on_batch: 0.015295212157070637  time_on_batch: 34.93393516540527\n",
      "Working on batch #:  66\n",
      "loss_on_batch: 0.0180539358407259  time_on_batch: 39.18023681640625\n",
      "Working on batch #:  67\n",
      "loss_on_batch: 0.028443584218621254  time_on_batch: 65.2896945476532\n",
      "Working on batch #:  68\n",
      "loss_on_batch: 0.031545065343379974  time_on_batch: 76.3461103439331\n",
      "Working on batch #:  69\n",
      "loss_on_batch: 0.030951879918575287  time_on_batch: 35.997769594192505\n",
      "Working on batch #:  70\n",
      "loss_on_batch: 0.020206443965435028  time_on_batch: 35.01214599609375\n",
      "Working on batch #:  71\n",
      "loss_on_batch: 0.020858600735664368  time_on_batch: 36.49709510803223\n",
      "Working on batch #:  72\n",
      "loss_on_batch: 0.02419094555079937  time_on_batch: 40.46364879608154\n",
      "Working on batch #:  73\n",
      "loss_on_batch: 0.024706849828362465  time_on_batch: 45.37671947479248\n",
      "Working on batch #:  74\n",
      "loss_on_batch: 0.024867674335837364  time_on_batch: 37.36139535903931\n",
      "Working on batch #:  75\n",
      "loss_on_batch: 0.01884165219962597  time_on_batch: 35.32598161697388\n",
      "Working on batch #:  76\n",
      "loss_on_batch: 0.015955723822116852  time_on_batch: 42.05584931373596\n",
      "Working on batch #:  77\n",
      "loss_on_batch: 0.015493607148528099  time_on_batch: 40.93490266799927\n",
      "Working on batch #:  78\n",
      "loss_on_batch: 0.024018986150622368  time_on_batch: 44.2025945186615\n",
      "Working on batch #:  79\n",
      "loss_on_batch: 0.020884951576590538  time_on_batch: 46.58393096923828\n",
      "Working on batch #:  80\n",
      "loss_on_batch: 0.032026760280132294  time_on_batch: 46.995906352996826\n",
      "Working on batch #:  81\n",
      "loss_on_batch: 0.023875676095485687  time_on_batch: 36.7192645072937\n",
      "Working on batch #:  82\n",
      "loss_on_batch: 0.02851695567369461  time_on_batch: 62.18218731880188\n",
      "Working on batch #:  83\n",
      "loss_on_batch: 0.02302011102437973  time_on_batch: 64.37184834480286\n",
      "Working on batch #:  84\n",
      "loss_on_batch: 0.014191039837896824  time_on_batch: 39.10728311538696\n",
      "Working on batch #:  85\n",
      "loss_on_batch: 0.025199150666594505  time_on_batch: 52.46339774131775\n",
      "Working on batch #:  86\n",
      "loss_on_batch: 0.02196567691862583  time_on_batch: 47.22732186317444\n",
      "Working on batch #:  87\n",
      "loss_on_batch: 0.01834084279835224  time_on_batch: 37.56795001029968\n",
      "Working on batch #:  88\n",
      "loss_on_batch: 0.02121913433074951  time_on_batch: 85.08446311950684\n",
      "Working on batch #:  89\n"
     ]
    }
   ],
   "source": [
    "from preprocess import *\n",
    "from scoring_metrics import *\n",
    "from cnn_utils import *\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import time\n",
    "\n",
    "saved_model_name = \"best_cnn\"\n",
    "\n",
    "'''Hyperparams dashboard'''\n",
    "margin = 0.15\n",
    "lr = 5**-3\n",
    "truncation_val = 75\n",
    "\n",
    "\n",
    "''' Data Prep '''\n",
    "word2vec = get_words_and_embeddings()\n",
    "id2Data = questionID_to_questionData_truncate(truncation_val)\n",
    "\n",
    "training_data = training_id_to_similar_different()\n",
    "trainingQuestionIds = list(training_data.keys())[:]\n",
    "\n",
    "dev_data = devTest_id_to_similar_different(dev=True)\n",
    "dev_question_ids = list(dev_data.keys())[:]\n",
    "\n",
    "test_data = devTest_id_to_similar_different(dev=False)\n",
    "test_question_ids = list(test_data.keys())\n",
    "\n",
    "\n",
    "''' Model Specs '''\n",
    "# CNN parameters\n",
    "input_size = len(word2vec[list(word2vec.keys())[0]])\n",
    "hidden_size = 200\n",
    "kernel_size = 3\n",
    "stride = 1\n",
    "padding = 0\n",
    "dilation = 1\n",
    "groups = 1\n",
    "bias = True\n",
    "\n",
    "# CNN model\n",
    "cnn = torch.nn.Sequential()\n",
    "cnn.add_module('conv', torch.nn.Conv1d(in_channels = input_size, out_channels = hidden_size, kernel_size = kernel_size, padding = padding, dilation = dilation, groups = groups, bias = bias))\n",
    "cnn.add_module('tanh', torch.nn.Tanh())\n",
    "\n",
    "# Loss function\n",
    "loss_function = torch.nn.MultiMarginLoss(margin=margin)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=lr, weight_decay=0.0001)\n",
    "\n",
    "\n",
    "''' Procedural parameters '''\n",
    "batch_size = 100\n",
    "num_differing_questions = 20\n",
    "num_epochs = 5\n",
    "num_batches = round(len(trainingQuestionIds)/batch_size)\n",
    "\n",
    "\n",
    "def train_model(cnn, optimizer, batch_ids, batch_data, word2vec, id2Data, truncation_val):\n",
    "    cnn.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    sequence_ids, dict_sequence_lengths = organize_ids_training(batch_ids, batch_data, num_differing_questions)\n",
    "\n",
    "    candidates_qs_tuples_matrix = construct_qs_matrix_training(sequence_ids, cnn, word2vec, id2Data, dict_sequence_lengths, input_size, num_differing_questions, truncation_val, candidates=True)\n",
    "    main_qs_tuples_matrix = construct_qs_matrix_training(batch_ids, cnn, word2vec, id2Data, dict_sequence_lengths, input_size, num_differing_questions, truncation_val, candidates=False)\n",
    "    similarity_matrix = torch.nn.functional.cosine_similarity(candidates_qs_tuples_matrix, main_qs_tuples_matrix, dim=2, eps=1e-08)\n",
    "\n",
    "    target = Variable(torch.LongTensor([0] * int(len(sequence_ids)/(1+num_differing_questions))))\n",
    "    loss_batch = loss_function(similarity_matrix, target)\n",
    "\n",
    "    loss_batch.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(\"loss_on_batch:\", loss_batch.data[0], \" time_on_batch:\", time.time() - start)\n",
    "    return\n",
    "\n",
    "\n",
    "def eval_model(cnn, ids, data, word2vec, id2Data, truncation_val):\n",
    "    cnn.eval()\n",
    "    sequence_ids, p_pluses_indices_dict = organize_test_ids(ids, data)\n",
    "\n",
    "    candidates_qs_tuples_matrix = construct_qs_matrix_testing(sequence_ids, cnn, word2vec, id2Data, input_size, num_differing_questions, truncation_val, candidates=True)\n",
    "    main_qs_tuples_matrix = construct_qs_matrix_testing(ids, cnn, word2vec, id2Data, input_size, num_differing_questions, truncation_val, candidates=False)\n",
    "\n",
    "    similarity_matrix = torch.nn.functional.cosine_similarity(candidates_qs_tuples_matrix, main_qs_tuples_matrix, dim=2, eps=1e-08)\n",
    "    MRR_score = get_MRR_score(similarity_matrix, p_pluses_indices_dict)\n",
    "    MAP_score = get_MAP_score(similarity_matrix, p_pluses_indices_dict)\n",
    "    avg_prec_at_1 = avg_precision_at_k(similarity_matrix, p_pluses_indices_dict, 1)\n",
    "    avg_prec_at_5 = avg_precision_at_k(similarity_matrix, p_pluses_indices_dict, 5) \n",
    "    return MRR_score, MAP_score, avg_prec_at_1, avg_prec_at_5\n",
    "\n",
    "\n",
    "'''Begin training'''\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    # Train on whole training data set\n",
    "    for batch in range(1, num_batches+1):\n",
    "        start = time.time()\n",
    "        questions_this_training_batch = trainingQuestionIds[batch_size * (batch - 1):batch_size * batch]\n",
    "        print(\"Working on batch #: \", batch)\n",
    "        train_model(cnn, optimizer, questions_this_training_batch, training_data, word2vec, id2Data, truncation_val)\n",
    "        \n",
    "    # Evaluate on dev and test sets for MRR score\n",
    "    dev_scores = eval_model(cnn, dev_question_ids, dev_data, word2vec, id2Data, truncation_val)\n",
    "    test_scores = eval_model(cnn, test_question_ids, test_data, word2vec, id2Data, truncation_val)\n",
    "    print(\"MRR score on dev set:\", dev_scores[0])\n",
    "    print(\"MRR score on test set:\", test_scores[0])\n",
    "    print(\"MAP score on dev set:\", dev_scores[1])\n",
    "    print(\"MAP score on test set:\", test_scores[1])\n",
    "    print(\"Precision at 1 score on dev set:\", dev_scores[2])\n",
    "    print(\"Precision at 1 score on test set:\", test_scores[2])\n",
    "    print(\"Precision at 5 score on dev set:\", dev_scores[3])\n",
    "    print(\"Precision at 5 score on test set:\", test_scores[3])\n",
    "\n",
    "    # Log results to local logs.txt file\n",
    "    with open('logs_cnn.txt', 'a') as log_file:\n",
    "        log_file.write('epoch: ' + str(epoch) + '\\n')\n",
    "        log_file.write('lr: ' + str(lr) +  ' marg: ' + str(margin) + '\\n' )        \n",
    "        log_file.write('dev_MRR: ' +  str(dev_scores[0]) + '\\n')\n",
    "        log_file.write('test_MRR: ' +  str(test_scores[0]) + '\\n')\n",
    "        log_file.write('dev_MAP: ' +  str(dev_scores[1]) + '\\n')\n",
    "        log_file.write('test_MAP: ' +  str(test_scores[1]) + '\\n')\n",
    "        log_file.write('dev_p_at_1: ' +  str(dev_scores[2]) + '\\n')\n",
    "        log_file.write('test_p_at_1: ' +  str(test_scores[2]) + '\\n')\n",
    "        log_file.write('dev_p_at_5: ' +  str(dev_scores[3]) + '\\n')\n",
    "        log_file.write('test_p_at_5: ' +  str(test_scores[3]) + '\\n')\n",
    "\n",
    "    # Save model for this epoch\n",
    "    torch.save(cnn, '../Pickle/' + saved_model_name + '_epoch' + str(epoch) + '.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5.3",
   "language": "python",
   "name": "py35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
